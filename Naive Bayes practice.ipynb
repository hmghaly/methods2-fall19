{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we'll walk through two implementations of naïve Bayes classifiers, both in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK has a [corpus of pet names coded for sex](http://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/areas/nlp/corpora/names/0.html). We will try to predict the sex using simple features of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5001 female names\n",
      "Loaded 2943 male names\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     /home/kbg/.anaconda3/share/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import nltk\n",
    "\n",
    "# I had to install the corpus ahead of time. But you only have to do this once.\n",
    "assert nltk.download(\"names\")\n",
    "\n",
    "female = nltk.corpus.names.words(\"female.txt\")\n",
    "print(f\"Loaded {len(female)} female names\")\n",
    "male = nltk.corpus.names.words(\"male.txt\")\n",
    "print(f\"Loaded {len(male)} male names\")\n",
    "\n",
    "# Then, we'll concatenate the data and turn it into (x, y) pairs.\n",
    "name_list = [(name, \"female\") for name in female] + [(name, \"male\") for name in male]\n",
    "\n",
    "# Then, we'll shuffle the data.\n",
    "random.seed(562)\n",
    "random.shuffle(name_list)  # This works in place.\n",
    "\n",
    "# Then, we'll split it into training and test data.\n",
    "train = name_list[:-1000]\n",
    "test = name_list[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a feature function. This one will take a name as input and returns a dictionary with string keys. I've adapted this from [chapter six of the NLTK book](https://www.nltk.org/book/ch06.html), but I tried to improve the code there a bit. Naturally you can always use tricks to avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'startswith(vowel)': False, 'endswith(vowel)': True, 'count(a)': 0, 'has(a)': False, 'count(b)': 0, 'has(b)': False, 'count(c)': 0, 'has(c)': False, 'count(d)': 1, 'has(d)': True, 'count(e)': 1, 'has(e)': True, 'count(f)': 0, 'has(f)': False, 'count(g)': 0, 'has(g)': False, 'count(h)': 0, 'has(h)': False, 'count(i)': 1, 'has(i)': True, 'count(j)': 0, 'has(j)': False, 'count(k)': 0, 'has(k)': False, 'count(l)': 0, 'has(l)': False, 'count(m)': 0, 'has(m)': False, 'count(n)': 0, 'has(n)': False, 'count(o)': 1, 'has(o)': True, 'count(p)': 0, 'has(p)': False, 'count(q)': 0, 'has(q)': False, 'count(r)': 0, 'has(r)': False, 'count(s)': 0, 'has(s)': False, 'count(t)': 0, 'has(t)': False, 'count(u)': 0, 'has(u)': False, 'count(v)': 0, 'has(v)': False, 'count(w)': 0, 'has(w)': False, 'count(x)': 0, 'has(x)': False, 'count(y)': 0, 'has(y)': False, 'count(z)': 0, 'has(z)': False}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "FeatureVector = Dict[str, object]\n",
    "\n",
    "\n",
    "def extract_features(name: str) -> FeatureVector:\n",
    "    \"\"\"Extracts features for a single example.\"\"\"\n",
    "    name_lowercase = name.casefold()\n",
    "    vowels = frozenset(\"aeiou\")\n",
    "    features = {}\n",
    "    features[\"startswith(vowel)\"] = name[0] in vowels\n",
    "    features[\"endswith(vowel)\"] = name[-1] in vowels\n",
    "    for char in string.ascii_lowercase:\n",
    "        count = name.count(char)\n",
    "        features[f\"count({char})\"] = count\n",
    "        features[f\"has({char})\"] = bool(count)\n",
    "    return features\n",
    "\n",
    "\n",
    "# An example dictionary vector.\n",
    "print(extract_features(\"Bodie\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [NLTK implementation](https://www.nltk.org/book/ch06.html) of naïve Bayes supports:\n",
    "\n",
    "* features of arbitrary types (so long as they're hashable)\n",
    "* multinomial classification (though we'll just give it a binary classification problem)\n",
    "\n",
    "[Internally](https://www.nltk.org/_modules/nltk/classify/naivebayes.html), it simply constructs $\\hat{P}(y = y')$ and $\\hat{P}(F_i \\mid y = y')$, using $c = .5$ (I believe) by default. Then, to predict, it computes the log posterior distribution $log \\hat{P}(y = y' \\mid \\mathcal{F})$ and returns the argmax. It is written in pure Python: consider taking a look!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK expects the training and test data laid out as a list of (string label, feature vector) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'startswith(vowel)': False, 'endswith(vowel)': False, 'count(a)': 1, 'has(a)': True, 'count(b)': 0, 'has(b)': False, 'count(c)': 0, 'has(c)': False, 'count(d)': 1, 'has(d)': True, 'count(e)': 2, 'has(e)': True, 'count(f)': 0, 'has(f)': False, 'count(g)': 0, 'has(g)': False, 'count(h)': 0, 'has(h)': False, 'count(i)': 0, 'has(i)': False, 'count(j)': 0, 'has(j)': False, 'count(k)': 0, 'has(k)': False, 'count(l)': 1, 'has(l)': True, 'count(m)': 0, 'has(m)': False, 'count(n)': 1, 'has(n)': True, 'count(o)': 0, 'has(o)': False, 'count(p)': 0, 'has(p)': False, 'count(q)': 0, 'has(q)': False, 'count(r)': 1, 'has(r)': True, 'count(s)': 0, 'has(s)': False, 'count(t)': 0, 'has(t)': False, 'count(u)': 0, 'has(u)': False, 'count(v)': 0, 'has(v)': False, 'count(w)': 0, 'has(w)': False, 'count(x)': 1, 'has(x)': True, 'count(y)': 0, 'has(y)': False, 'count(z)': 0, 'has(z)': False}, 'male')\n"
     ]
    }
   ],
   "source": [
    "nltk_train_set = [(extract_features(name), label) for (name, label) in train]\n",
    "\n",
    "# An example pair.\n",
    "print(nltk_train_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is actually a class method that returns a model object of \n",
    "# type `NaiveBayesClassifier`.\n",
    "nltk_clf = nltk.classify.naivebayes.NaiveBayesClassifier.train(nltk_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict, we simply call the `classify` method with a feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n"
     ]
    }
   ],
   "source": [
    "lambda_features = extract_features(\"Lambda\")  # Weird pet name, I know.\n",
    "print(nltk_clf.classify(lambda_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK implementation also can show us which features it determined to be most informative, providing them as a \"X to 1\" ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                count(y) = 2              female : male   =      5.1 : 1.0\n",
      "                count(a) = 3              female : male   =      4.7 : 1.0\n",
      "                count(f) = 2                male : female =      3.9 : 1.0\n",
      "                  has(f) = True             male : female =      3.7 : 1.0\n",
      "                count(e) = 3              female : male   =      3.6 : 1.0\n",
      "                count(f) = 1                male : female =      3.6 : 1.0\n",
      "                count(w) = 1                male : female =      3.3 : 1.0\n",
      "                  has(w) = True             male : female =      3.3 : 1.0\n",
      "                count(u) = 2                male : female =      3.2 : 1.0\n",
      "                count(i) = 3                male : female =      3.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nltk_clf.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate. Accuracy (the percentage of correct classifications) on a held-out test set seems like an obvious measure here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7370\n"
     ]
    }
   ],
   "source": [
    "nltk_test_set = [(extract_features(name), label) for (name, label) in test]\n",
    "print(f\"{nltk.classify.util.accuracy(nltk_clf, nltk_test_set):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Scikit-learn implementation](https://scikit-learn.org/stable/modules/naive_bayes.html) of naïve Bayes supports:\n",
    "\n",
    "* numerical features only\n",
    "* multinomial classification (though we'll just give it a binary classification problem)\n",
    "\n",
    "The desired value of $c$ is passed to the constructor using the `alpha` keyword (and defaults to $c = 1$).\n",
    "\n",
    "Whereas NLTK wanted data laid out using lists of (string label, feature vector) pairs, Scikit-learn wants separate lists (or arrays) of numerical feature vectors ($X$ in their notation) and string labels ($Y$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 1. 2. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.feature_extraction\n",
    "\n",
    "skl_vectorizer = sklearn.feature_extraction.DictVectorizer(sparse=False)\n",
    "# This first prepares the encoding (`fit`) then applies it to the data (`transform`).\n",
    "skl_train_x = skl_vectorizer.fit_transform(extract_features(name) for (name, _) in train)\n",
    "\n",
    "# An example numerical feature vector.\n",
    "print(skl_train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# We also need to pull out Y; we'll encode it using a boolean where female == True.\n",
    "skl_train_y = [sex == \"female\" for (_, sex) in train]\n",
    "\n",
    "# An example boolean class vector.\n",
    "print(skl_train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.naive_bayes\n",
    "\n",
    "# Unlike in NLTK, we create the classifier object before we train.\n",
    "skl_clf = sklearn.naive_bayes.MultinomialNB()\n",
    "_ = skl_clf.fit(skl_train_x, skl_train_y)  # Assignment just to silence it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict, we simply call the `predict` method with an iterable of feature vectors. Note this is unlike NLTK's `classify` method, which only takes a single feature vector at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_clf.predict(skl_vectorizer.transform(extract_features(\"Lambda\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can evaluate, using test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7460\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "# `fit` or `fit_transform` should only be called once; after that we can only `transform`.\n",
    "skl_test_x = skl_vectorizer.transform(extract_features(name) for (name, _) in test)\n",
    "skl_test_y = [sex == \"female\" for (_, sex) in test]\n",
    "# Predicts the labels for the test data.\n",
    "skl_pred_y = skl_clf.predict(skl_test_x)\n",
    "print(f\"{sklearn.metrics.accuracy_score(skl_test_y, skl_pred_y):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is quite similar to the NLTK implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve the above examples in one or more of the following ways:\n",
    "\n",
    "* compute an absolute baseline: how hard is this task if we just guessed the most likely label?\n",
    "* write functions for repeated operations like feature and/or class encoding\n",
    "* write classes which wraps the two classifier with a more friendly interface that automatically handles feature encoding for you\n",
    "* modify the feature extractor for better accuracy\n",
    "* try another type of classifier from NLTK and/or Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /Users/hmghaly/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "Loaded 5001 female names\n",
      "Loaded 2943 male names\n",
      "[('Gilburt', 'male'), ('Robina', 'female'), ('Kissie', 'female'), ('Allegra', 'female'), ('Melantha', 'female'), ('Carmen', 'female'), ('Verile', 'female'), ('Ric', 'male'), ('Sela', 'female'), ('Tine', 'female')]\n",
      "[('Garp', 'male'), ('Elli', 'female'), ('Weidar', 'male'), ('Dosi', 'female'), ('Osbert', 'male'), ('Freemon', 'male'), ('Gusty', 'female'), ('Aurore', 'female'), ('Mella', 'female'), ('Mabel', 'female')]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import nltk\n",
    "\n",
    "# I had to install the corpus ahead of time. But you only have to do this once.\n",
    "assert nltk.download(\"names\")\n",
    "\n",
    "female = nltk.corpus.names.words(\"female.txt\")\n",
    "print(f\"Loaded {len(female)} female names\")\n",
    "male = nltk.corpus.names.words(\"male.txt\")\n",
    "print(f\"Loaded {len(male)} male names\")\n",
    "\n",
    "# Then, we'll concatenate the data and turn it into (x, y) pairs.\n",
    "name_list = [(name, \"female\") for name in female] + [(name, \"male\") for name in male]\n",
    "#\n",
    "#print(len(name_list))\n",
    "# Then, we'll shuffle the data.\n",
    "random.seed(0)\n",
    "random.shuffle(name_list)  # This works in place.\n",
    "print(name_list[:10])\n",
    "\n",
    "# random.shuffle(name_list)  # This works in place.\n",
    "# print(name_list[:10])\n",
    "\n",
    "# Then, we'll split it into training and test data.\n",
    "train = name_list[:-1000]\n",
    "test = name_list[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Lois', 'female'),\n",
       " ('Jacynth', 'female'),\n",
       " ('Andrea', 'male'),\n",
       " ('Cordy', 'female'),\n",
       " ('Benton', 'male'),\n",
       " ('Sherri', 'female'),\n",
       " ('Quint', 'male'),\n",
       " ('Karrie', 'female'),\n",
       " ('Briggs', 'male'),\n",
       " ('Bearnard', 'male')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alwin',\n",
       " 'Amadeus',\n",
       " 'Ambros',\n",
       " 'Ambrose',\n",
       " 'Ambrosi',\n",
       " 'Ambrosio',\n",
       " 'Ambrosius',\n",
       " 'Amery',\n",
       " 'Amory',\n",
       " 'Amos']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gilburt', 'male'), ('Robina', 'female'), ('Kissie', 'female'), ('Allegra', 'female'), ('Melantha', 'female'), ('Carmen', 'female'), ('Verile', 'female'), ('Ric', 'male'), ('Sela', 'female'), ('Tine', 'female')]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "name_list = [(name, \"female\") for name in female] + [(name, \"male\") for name in male]\n",
    "random.seed(0)\n",
    "random.shuffle(name_list)  # This works in place.\n",
    "print(name_list[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Corinne', 'female'), ('Reece', 'male'), ('Hazel', 'male'), ('Wakefield', 'male'), ('Elly', 'female'), ('Rockwell', 'male'), ('Zelig', 'male'), ('Eddie', 'male'), ('Dell', 'female'), ('Salem', 'male')]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#name_list = [(name, \"female\") for name in female] + [(name, \"male\") for name in male]\n",
    "random.seed(0)\n",
    "random.shuffle(name_list)  # This works in place.\n",
    "print(name_list[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startswith(vowel) False\n",
      "endswith(vowel) True\n",
      "endswith(a) False\n",
      "endswith(o) True\n",
      "endswith o\n",
      "count(a) 1\n",
      "has(a) True\n",
      "count(b) 0\n",
      "has(b) False\n",
      "count(c) 1\n",
      "has(c) True\n",
      "count(d) 0\n",
      "has(d) False\n",
      "count(e) 0\n",
      "has(e) False\n",
      "count(f) 0\n",
      "has(f) False\n",
      "count(g) 0\n",
      "has(g) False\n",
      "count(h) 0\n",
      "has(h) False\n",
      "count(i) 0\n",
      "has(i) False\n",
      "count(j) 0\n",
      "has(j) False\n",
      "count(k) 0\n",
      "has(k) False\n",
      "count(l) 1\n",
      "has(l) True\n",
      "count(m) 0\n",
      "has(m) False\n",
      "count(n) 0\n",
      "has(n) False\n",
      "count(o) 1\n",
      "has(o) True\n",
      "count(p) 0\n",
      "has(p) False\n",
      "count(q) 0\n",
      "has(q) False\n",
      "count(r) 1\n",
      "has(r) True\n",
      "count(s) 0\n",
      "has(s) False\n",
      "count(t) 0\n",
      "has(t) False\n",
      "count(u) 0\n",
      "has(u) False\n",
      "count(v) 0\n",
      "has(v) False\n",
      "count(w) 0\n",
      "has(w) False\n",
      "count(x) 0\n",
      "has(x) False\n",
      "count(y) 0\n",
      "has(y) False\n",
      "count(z) 0\n",
      "has(z) False\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "FeatureVector = Dict[str, object]\n",
    "\n",
    "\n",
    "def extract_features(name: str) -> FeatureVector:\n",
    "    \"\"\"Extracts features for a single example.\"\"\"\n",
    "    name_lowercase = name.casefold()\n",
    "    vowels = frozenset(\"aeiou\")\n",
    "    features = {}\n",
    "    features[\"startswith(vowel)\"] = name_lowercase[0] in vowels\n",
    "    features[\"endswith(vowel)\"] = name_lowercase[-1] in vowels\n",
    "    features[\"endswith(a)\"] = name_lowercase[-1] == \"a\"\n",
    "    features[\"endswith(o)\"] = name_lowercase[-1] == \"o\"    \n",
    "    features[\"endswith\"] = name_lowercase[-1]\n",
    "    for char in string.ascii_lowercase:\n",
    "        count = name_lowercase.count(char)\n",
    "        features[f\"count({char})\"] = count\n",
    "        features[f\"has({char})\"] = bool(count)\n",
    "    return features\n",
    "# An example dictionary vector.\n",
    "for a,b in extract_features(\"Carlo\").items():\n",
    "    print(a,b)\n",
    "#print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'startswith(vowel)': False, 'endswith(vowel)': False, 'endswith(a)': False, 'endswith(o)': False, 'endswith': 'p', 'count(a)': 1, 'has(a)': True, 'count(b)': 0, 'has(b)': False, 'count(c)': 0, 'has(c)': False, 'count(d)': 0, 'has(d)': False, 'count(e)': 0, 'has(e)': False, 'count(f)': 0, 'has(f)': False, 'count(g)': 1, 'has(g)': True, 'count(h)': 0, 'has(h)': False, 'count(i)': 0, 'has(i)': False, 'count(j)': 0, 'has(j)': False, 'count(k)': 0, 'has(k)': False, 'count(l)': 0, 'has(l)': False, 'count(m)': 0, 'has(m)': False, 'count(n)': 0, 'has(n)': False, 'count(o)': 0, 'has(o)': False, 'count(p)': 1, 'has(p)': True, 'count(q)': 0, 'has(q)': False, 'count(r)': 1, 'has(r)': True, 'count(s)': 0, 'has(s)': False, 'count(t)': 0, 'has(t)': False, 'count(u)': 0, 'has(u)': False, 'count(v)': 0, 'has(v)': False, 'count(w)': 0, 'has(w)': False, 'count(x)': 0, 'has(x)': False, 'count(y)': 0, 'has(y)': False, 'count(z)': 0, 'has(z)': False}, 'male')\n",
      "('Garp', 'male')\n"
     ]
    }
   ],
   "source": [
    "nltk_train_set = [(extract_features(name), label) for (name, label) in train]\n",
    "\n",
    "# An example pair.\n",
    "print(nltk_train_set[0])\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'startswith(vowel)': False, 'endswith(vowel)': True, 'endswith(a)': False, 'endswith(o)': False, 'endswith': 'e', 'count(a)': 1, 'has(a)': True, 'count(b)': 0, 'has(b)': False, 'count(c)': 0, 'has(c)': False, 'count(d)': 0, 'has(d)': False, 'count(e)': 2, 'has(e)': True, 'count(f)': 0, 'has(f)': False, 'count(g)': 0, 'has(g)': False, 'count(h)': 0, 'has(h)': False, 'count(i)': 0, 'has(i)': False, 'count(j)': 0, 'has(j)': False, 'count(k)': 0, 'has(k)': False, 'count(l)': 0, 'has(l)': False, 'count(m)': 0, 'has(m)': False, 'count(n)': 2, 'has(n)': True, 'count(o)': 0, 'has(o)': False, 'count(p)': 0, 'has(p)': False, 'count(q)': 0, 'has(q)': False, 'count(r)': 0, 'has(r)': False, 'count(s)': 0, 'has(s)': False, 'count(t)': 2, 'has(t)': True, 'count(u)': 0, 'has(u)': False, 'count(v)': 0, 'has(v)': False, 'count(w)': 0, 'has(w)': False, 'count(x)': 0, 'has(x)': False, 'count(y)': 0, 'has(y)': False, 'count(z)': 0, 'has(z)': False}, 'female')\n",
      "('Nanette', 'female')\n"
     ]
    }
   ],
   "source": [
    "print(nltk_train_set[100])\n",
    "print(train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk_clf = nltk.classify.naivebayes.NaiveBayesClassifier.train(nltk_train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n"
     ]
    }
   ],
   "source": [
    "name=\"Campbel\"\n",
    "features=extract_features(name)\n",
    "features\n",
    "print(nltk_clf.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                endswith = 'k'              male : female =     71.6 : 1.0\n",
      "                endswith = 'a'            female : male   =     35.4 : 1.0\n",
      "             endswith(a) = True           female : male   =     35.3 : 1.0\n",
      "                endswith = 'f'              male : female =     16.9 : 1.0\n",
      "                endswith = 'p'              male : female =     11.3 : 1.0\n",
      "                endswith = 'd'              male : female =     11.1 : 1.0\n",
      "                endswith = 'v'              male : female =     10.0 : 1.0\n",
      "                endswith = 'm'              male : female =      8.6 : 1.0\n",
      "             endswith(o) = True             male : female =      7.8 : 1.0\n",
      "                endswith = 'o'              male : female =      7.8 : 1.0\n",
      "                endswith = 'r'              male : female =      6.6 : 1.0\n",
      "                endswith = 'w'              male : female =      6.3 : 1.0\n",
      "                endswith = 'g'              male : female =      4.8 : 1.0\n",
      "                endswith = 's'              male : female =      4.7 : 1.0\n",
      "                count(a) = 3              female : male   =      4.5 : 1.0\n",
      "                count(w) = 1                male : female =      4.3 : 1.0\n",
      "                  has(w) = True             male : female =      4.3 : 1.0\n",
      "                endswith = 't'              male : female =      4.0 : 1.0\n",
      "                count(m) = 3                male : female =      4.0 : 1.0\n",
      "                endswith = 'j'              male : female =      4.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nltk_clf.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757\n"
     ]
    }
   ],
   "source": [
    "nltk_test_set = [(extract_features(name), label) for (name, label) in test]\n",
    "accuracy=nltk.classify.util.accuracy(nltk_clf, nltk_test_set)\n",
    "print(accuracy)\n",
    "#print(f\"{nltk.classify.util.accuracy(nltk_clf, nltk_test_set):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
